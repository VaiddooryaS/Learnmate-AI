# -*- coding: utf-8 -*-
"""learnmate-ai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iE69-91SmYBlCOAqOwPFzRN5eJngYSBj
"""

# Streamlit + dependencies
!pip install -q streamlit yt-dlp PyMuPDF openai-whisper torch nltk keybert scikit-learn spacy deep-translator matplotlib networkx google-generativeai streamlit-javascript transformers pyngrok

pip install --upgrade google-generativeai

!ngrok config add-authtoken 33H0WCQ2k3Wn4CwKaRYbuCz7jcg_3BWqjwjbKXy6kF3W8HWFq

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# from transformers import BartTokenizer, BartForConditionalGeneration
# 
# import torch
# import re
# import textwrap
# 
# import streamlit as st
# import os
# import fitz
# import whisper
# import nltk
# import subprocess
# import matplotlib.pyplot as plt
# import networkx as nx
# from heapq import nlargest
# from collections import Counter
# from nltk.tokenize import sent_tokenize
# from keybert import KeyBERT
# from deep_translator import GoogleTranslator
# import google.generativeai as genai
# import yt_dlp
# 
# 
# # Load model once at top level (to avoid reloading on every button click)
# @st.cache_resource
# def load_bart_model():
#     tokenizer = BartTokenizer.from_pretrained("facebook/bart-large-cnn")
#     model2 = BartForConditionalGeneration.from_pretrained("facebook/bart-large-cnn")
#     return tokenizer, model2
# 
# tokenizer, model2 = load_bart_model()
# 
# # Helper functions
# def dynamic_sentence_token_chunking(text, tokenizer, desired_sent_per_chunk=5, max_tokens=1000, overlap=1):
#     text = re.sub(r'\s+', ' ', text).strip()
#     sentences = sent_tokenize(text)
#     chunks = []
#     i = 0
#     total_sentences = len(sentences)
# 
#     while i < total_sentences:
#         sent_count = desired_sent_per_chunk
#         while sent_count > 0:
#             candidate = " ".join(sentences[i:i + sent_count])
#             token_len = len(tokenizer.encode(candidate, add_special_tokens=False))
#             if token_len <= max_tokens:
#                 chunks.append(candidate.strip())
#                 i += max(sent_count - overlap, 1)
#                 break
#             else:
#                 sent_count -= 1
# 
#         if sent_count == 0:
#             chunks.append(sentences[i].strip())
#             i += 1
# 
#     return chunks
# 
# def summarize_chunk(text, percentage=0.4):
#     input_ids = tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=1024)
#     input_length = input_ids.shape[1]
# 
#     if input_length > 200:
#         min_length = 50
#     elif input_length > 150:
#         min_length = 35
#     elif input_length > 100:
#         min_length = 25
#     elif input_length > 50:
#         min_length = 15
#     else:
#         min_length = 10
# 
#     max_length = max(int(input_length * percentage), min_length + 1)
# 
#     summary_ids = model2.generate(
#         input_ids,
#         max_length=max_length,
#         min_length=min_length,
#         num_beams=4,
#         length_penalty=1.0,
#         early_stopping=True
#     )
#     return tokenizer.decode(summary_ids[0], skip_special_tokens=True)
# 
# def summarize_long_text(text, sentence_per_chunk=5, percentage=0.4):
#     chunks = dynamic_sentence_token_chunking(
#         text, tokenizer,
#         desired_sent_per_chunk=sentence_per_chunk,
#         max_tokens=1000,
#         overlap=1
#     )
# 
#     all_summaries = []
#     for chunk in chunks:
#         summary = summarize_chunk(chunk, percentage=percentage)
#         all_summaries.append(summary)
# 
#     intermediate_summary = " ".join(all_summaries)
#     final_summary = summarize_chunk(intermediate_summary, percentage=percentage)
# 
#     return intermediate_summary
# 
# 
# 
# 
# 
# nltk.download('punkt')
# 
# model = whisper.load_model("base")
# genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
# gemini_model = genai.GenerativeModel("models/gemini-2.5-flash")
# 
# 
# # Session states
# for key in ['text', 'summary', 'translated', 'questions', 'answers', 'user_inputs']:
#     if key not in st.session_state:
#         st.session_state[key] = "" if key in ['text', 'summary', 'translated'] else []
# st.session_state.setdefault('pdf_uploaded', False)
# st.session_state.setdefault('cookies_uploaded', False)
# st.session_state.setdefault('lang', 'hi')
# 
# st.set_page_config(layout="wide")
# st.title("üìö LearnMate AI ‚Äì Multi-tool EdTech Assistant")
# 
# # Step 1: Inputs
# st.header("Step 1: Upload PDF or Enter YouTube URL")
# youtube_url = st.text_input("YouTube URL")
# pdf_file = st.file_uploader("Upload PDF", type=['pdf'])
# cookies_file = st.file_uploader("Upload cookies.txt (for YouTube)", type=['txt'])
# submit = st.button("Submit")
# 
# if cookies_file:
#     with open("cookies.txt", "wb") as f:
#         f.write(cookies_file.read())
#     st.session_state.cookies_uploaded = True
#     st.success("‚úÖ Cookies uploaded.")
# 
# if pdf_file:
#     with open("temp.pdf", "wb") as f:
#         f.write(pdf_file.read())
#     st.session_state.pdf_uploaded = True
#     st.success("‚úÖ PDF uploaded.")
# 
# # Step 2: Process Text
# if submit:
#     st.session_state.text = ""
#     if youtube_url:
#         if not st.session_state.cookies_uploaded:
#             st.warning("Upload cookies.txt before submitting.")
#         else:
#             ydl_opts = {
#                 'format': 'bestaudio/best',
#                 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}],
#                 'outtmpl': 'audio.%(ext)s',
#                 'cookiefile': 'cookies.txt',
#                 'quiet': True
#             }
#             with yt_dlp.YoutubeDL(ydl_opts) as ydl:
#                 ydl.download([youtube_url])
#             result = model.transcribe("audio.mp3", fp16=False)
#             st.session_state.text = result["text"]
#             os.remove("audio.mp3")
#     elif st.session_state.pdf_uploaded:
#         doc = fitz.open("temp.pdf")
#         for page in doc:
#             st.session_state.text += page.get_text("text", sort=True)
#         os.remove("temp.pdf")
#     else:
#         st.warning("Please provide a YouTube URL or upload a PDF.")
# 
# # Page selector
# page = st.selectbox("Choose a module:", ["Summarize", "Help You Learn", "Quiz"])
# 
# # --- SUMMARIZE ---
# if page == "Summarize" and st.session_state.text:
#     st.subheader("Step 2: Extracted Text and Summary")
# 
#     col1, col2 = st.columns([6, 1])
#     with col1:
#         st.markdown("**Extractive Summary**")
#     with col2:
#         if st.button("Summarize"):
# 
#             st.info("Generating abstractive summary... Please wait ‚è≥")
#             st.session_state.summary = summarize_long_text(st.session_state.text, sentence_per_chunk=10, percentage=0.5)
# 
#     colL, colR = st.columns(2)
#     with colL:
#         st.text_area("Extracted Text", value=st.session_state.text, height=400)
#     with colR:
#         st.text_area("Summary", value=st.session_state.summary, height=400)
# 
#     # Step 3: Translation
#     st.subheader("Step 3: Translation")
#     lang_col, btn1_col, btn2_col = st.columns([3, 2, 2])
#     st.session_state.lang = lang_col.text_input("Language code (e.g., 'hi')", value=st.session_state.lang)
# 
#     def translate_chunks(text, lang):
#         sentences = sent_tokenize(text)
#         result = ""
#         for i in range(0, len(sentences), 5):
#             chunk = " ".join(sentences[i:i+5])
#             result += GoogleTranslator(source='auto', target=lang).translate(chunk) + " "
#         return result.strip()
# 
#     if btn1_col.button("Translate Extracted Text"):
#         st.session_state.translated = translate_chunks(st.session_state.text, st.session_state.lang)
#     if btn2_col.button("Translate Summary"):
#         st.session_state.translated = translate_chunks(st.session_state.summary, st.session_state.lang)
# 
#     st.text_area("Translated Output", value=st.session_state.translated, height=200)
# 
# # --- MINDMAP + FLASHCARDS ---
# if page == "Help You Learn" and st.session_state.text:
#     st.subheader("Step 4: Mind Map")
#     keywords = [kw[0] for kw in KeyBERT().extract_keywords(st.session_state.text, top_n=15)]
#     G = nx.Graph()
#     G.add_node("Text")
#     for kw in keywords:
#         G.add_node(kw)
#         G.add_edge("Text", kw)
# 
#     fig, ax = plt.subplots(figsize=(2,2))
#     fig.subplots_adjust(left=0.5, right=2, top=1.5, bottom=0.5)
#     ax.axis('off')
#     nx.draw(G, with_labels=True, node_color='skyblue', node_size=800, font_size=4, ax=ax)
#     st.pyplot(fig,use_container_width=False, clear_figure=True)
# 
#     st.subheader("Step 5: Gemini Flashcards")
#     num = st.slider("Select number of flashcards:", 5, 50, 10)
#     if st.button("Generate Flashcards"):
#         prompt = (
#             f"You are a flashcard generator. Based ONLY on the following text, create exactly {num} flashcards.\n"
#             "Each card format:\nFront: <question>\nBack: <answer>\nOnly valid flashcards.\n"
#             f"\nTEXT:\n{st.session_state.text}"
#         )
#         try:
#             res = gemini_model.generate_content(prompt)
#             raw = res.text.strip().split("\n")
#             cards = []
#             for i in range(len(raw) - 1):
#                 if raw[i].lower().startswith("front:") and raw[i+1].lower().startswith("back:"):
#                     front = raw[i][6:].strip()
#                     back = raw[i+1][5:].strip()
#                     cards.append((front, back))
# 
#             html_cards = """
#             <style>
#             .scroll-container { overflow-y: auto; max-width: 100%; padding: 10px; background-color: #f9f9f9; height: 400px;}
#             .card-grid {display: grid; grid-template-columns: repeat(5, 1fr); gap: 15px; justify-items: center;width: fit-content; }
#             .flip-card {
#               width: 200px; height: 150px; perspective: 1000px; cursor: pointer;
#             }
#             .flip-card-inner {
#               position: relative; width: 100%; height: 100%; text-align: center;
#               transition: transform 0.6s; transform-style: preserve-3d;
#             }
#             .flip-card.flipped .flip-card-inner {
#               transform: rotateY(180deg);
#             }
#             .flip-card-front, .flip-card-back {
#               position: absolute; width: 100%; height: 100%; border: 1px solid #ccc;
#               border-radius: 8px; backface-visibility: hidden; background: #fff;
#               display: flex; align-items: center; justify-content: center;
#               font-size: 14px; padding: 10px; box-sizing: border-box;
#             }
#             .flip-card-front { color: red; }
#             .flip-card-back { transform: rotateY(180deg); color: green; }
#             </style>
#             <script>
#             function flipCard(cardId) {
#               var card = document.getElementById(cardId);
#               card.classList.toggle('flipped');
#             }
#             </script>
#             <div class="scroll-container"><div class="card-grid">
#             """
# 
#             for idx, (front, back) in enumerate(cards):
#                 html_cards += f"""
#                 <div class="flip-card" id="card{idx}" onclick="flipCard('card{idx}')">
#                   <div class="flip-card-inner">
#                     <div class="flip-card-front"><b>{front}</b></div>
#                     <div class="flip-card-back"><b>{back}</b></div>
#                   </div>
#                 </div>
#                 """
#             html_cards += "</div></div>"
#             st.components.v1.html(html_cards, height=500)
# 
#         except Exception as e:
#             st.error(f"Gemini error: {e}")
# 
# from streamlit.components.v1 import html
# from streamlit_javascript import st_javascript
# 
# # --- QUIZ ---
# if page == "Quiz" and st.session_state.text:
#     st.subheader("Step 6: One-word Answer Quiz")
# 
#     # Generate questions
#     if st.button("Generate Questions"):
#         prompt = (
#             "From this text, generate 10 to 50 factual one-word-answer questions.\n"
#             "Use format:\nQ: <question>\nA: <answer>\n"
#             f"\nTEXT:\n{st.session_state.text}"
#         )
#         try:
#             res = gemini_model.generate_content(prompt)
#             raw = res.text.strip().split("\n")
#             st.session_state.questions, st.session_state.answers = [], []
#             for i in range(0, len(raw)-1):
#                 if raw[i].startswith("Q:") and raw[i+1].startswith("A:"):
#                     st.session_state.questions.append(raw[i][2:].strip())
#                     st.session_state.answers.append(raw[i+1][2:].strip())
#             st.session_state.user_inputs = ["" for _ in st.session_state.questions]
#         except Exception as e:
#             st.error(f"Gemini error: {e}")
# 
#     # Show questions and accept user input
#     if st.session_state.questions:
#         for i, q in enumerate(st.session_state.questions):
#             st.markdown(f"**Q{i+1}: {q}**")
#             st.session_state.user_inputs[i] = st.text_input(
#                 "Your Answer:", key=f"user_input_{i}", value=st.session_state.user_inputs[i]
#             )
# 
#     # # View Correct Answers
#     # if st.button("View Correct Answers"):
#     #     for i, (q, a) in enumerate(zip(st.session_state.questions, st.session_state.answers)):
#     #         st.markdown(f"**Q{i+1}: {q}**\n‚úÖ Correct Answer: {a}")
# 
#     # Evaluate Answers
#     if st.button("Evaluate Answers"):
#       import re
#       import streamlit.components.v1 as components
# 
#       def clean_text(text):
#           return re.sub(r'[^\w\s]', '', text).strip().lower()
# 
#       correct, incorrect = 0, 0  # ‚úÖ Initialize counters
# 
#       display_answers = """
#       <div style="max-height:400px; overflow-y:auto; padding:15px; border:1px solid #ccc; border-radius:10px; background:#f9f9f9;">
#       """
# 
#       for i, (q, a, u) in enumerate(zip(
#           st.session_state.questions,
#           st.session_state.answers,
#           st.session_state.user_inputs
#       )):
#           clean_user = clean_text(u)
#           clean_answer = clean_text(a)
# 
#           if clean_user == clean_answer and clean_user != "":
#               correct += 1
#           else:
#               incorrect += 1
# 
#           is_correct = clean_user == clean_answer and clean_user != ""
#           color = "green" if is_correct else "red"
# 
#           display_answers += f"""
#           <div style="margin-bottom:15px;">
#               <p><b>Q{i+1}:</b> {q}</p>
#               <p style="color:blue;">Your Answer: {u}</p>
#               <p style="color:{color};">Correct Answer: {a}</p>
#               <hr>
#           </div>
#           """
# 
#       display_answers += "</div>"
# 
#       # Show inside scrollable HTML container
#       components.html(display_answers, height=420)
# 
#       # Optionally, show a summary score
#       st.success(f"‚úÖ Correct: {correct} | ‚ùå Incorrect: {incorrect}")
# 
#     # Show pie chart
#       st.subheader("üìä Score Pie Chart")
#       labels = ['Correct', 'Incorrect']
#       sizes = [correct, incorrect]
#       fig, ax = plt.subplots(figsize=(2, 2))
#       ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['green', 'red'])
#       ax.axis('equal')
#       st.pyplot(fig, use_container_width=False, clear_figure=True)
# 
# 
# 
# import os
# os.environ["GEMINI_API_KEY"] = "AIzaSyCV0vGr_VAify621CWa7DucTvwyAnAlGjk"
# 
# 
#

from pyngrok import ngrok
ngrok.kill()  # Terminate any existing tunnels
public_url = ngrok.connect(8501)
print("üåç Streamlit URL:", public_url)
!streamlit run /content/app.py --server.port 8501 --server.address 0.0.0.0